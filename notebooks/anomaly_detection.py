# /// script
# requires-python = ">=3.12"
# dependencies = [
#     "marimo",
#     "polars",
#     "altair",
#     "pandas",
# ]
# ///
"""
Anomaly Detection

Detect suspicious patterns in the audit log:
- Off-hours activity
- Bulk operations
- Dangerous actions
- Unusual IP addresses
"""

import marimo


__generated_with = "0.18.4"
app = marimo.App(width="medium")


@app.cell
def _():
    import altair as alt
    import marimo as mo
    import polars as pl

    return alt, mo, pl


@app.cell
def _(mo):
    mo.md(r"""
    # âš ï¸ ç•°å¸¸æ¤œçŸ¥

    Audit Logå†…ã®ç–‘ã‚ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºã—ã¾ã™ã€‚
    """)


@app.cell
def _(mo):
    file_upload = mo.ui.file(
        filetypes=[".json", ".ndjson"],
        multiple=True,  # è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠã‚’æœ‰åŠ¹åŒ–
        label="Audit Logãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
    )
    file_upload
    return (file_upload,)


@app.cell
def _(file_upload, mo, pl):
    import json
    from datetime import datetime

    def parse_audit_log_file(file_info) -> list[dict]:
        """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦ãƒ¬ã‚³ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã‚’è¿”ã™"""
        content = file_info.contents.decode("utf-8").strip()

        if file_info.name.endswith(".ndjson") or not content.startswith("["):
            lines = [json.loads(line) for line in content.split("\n") if line.strip()]
        else:
            lines = json.loads(content)

        records = []
        for entry in lines:
            ts = entry.get("@timestamp", entry.get("timestamp"))
            if isinstance(ts, (int, float)):
                if ts > 1e12:
                    ts = datetime.fromtimestamp(ts / 1000)
                else:
                    ts = datetime.fromtimestamp(ts)
            else:
                ts = datetime.fromisoformat(str(ts))

            records.append(
                {
                    "timestamp": ts,
                    "action": entry.get("action", "unknown"),
                    "actor": entry.get("actor", "unknown"),
                    "actor_ip": entry.get("actor_ip"),
                    "org": entry.get("org", "unknown"),
                    "repo": entry.get("repo"),
                    "_source_file": file_info.name,
                }
            )
        return records

    # è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    df = None
    if file_upload.value:
        all_records = []
        file_summaries = []

        for file_info in file_upload.value:
            records = parse_audit_log_file(file_info)
            all_records.extend(records)
            file_summaries.append(f"- `{file_info.name}`: {len(records):,} ã‚¤ãƒ™ãƒ³ãƒˆ")

        df = pl.DataFrame(all_records)
        file_count = len(file_upload.value)
        files_info = "\n".join(file_summaries)
        file_upload_result = f"""
        âœ… **{len(df):,} ã‚¤ãƒ™ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ** ({file_count} ãƒ•ã‚¡ã‚¤ãƒ«)

        {files_info}
        """
    else:
        file_upload_result = "â³ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
    mo.md(file_upload_result)
    return (df,)


@app.cell
def _(df, mo):
    mo.stop(df is None, mo.md("ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„"))


@app.cell
def _(df, mo, pl):
    # Get data range
    min_ts = df.select(pl.col("timestamp").min()).item()
    max_ts = df.select(pl.col("timestamp").max()).item()

    # Date range selector
    date_range = mo.ui.date_range(
        start=min_ts.date(),
        stop=max_ts.date(),
        label="åˆ†æå¯¾è±¡æœŸé–“",
    )
    mo.md(f"""
    ## ğŸ“… ãƒ‡ãƒ¼ã‚¿æœŸé–“

    - **å…¨ãƒ‡ãƒ¼ã‚¿**: {min_ts.date()} ã€œ {max_ts.date()} ({(max_ts - min_ts).days} æ—¥é–“)
    """)
    return (date_range,)


@app.cell
def _(date_range, mo):
    date_range


@app.cell
def _(date_range, datetime, df, mo, pl):
    # Filter by date range
    if date_range.value:
        start_date, end_date = date_range.value
        start_dt = datetime.combine(start_date, datetime.min.time())
        end_dt = datetime.combine(end_date, datetime.max.time())
        filtered_df = df.filter(
            (pl.col("timestamp") >= start_dt) & (pl.col("timestamp") <= end_dt)
        )
    else:
        filtered_df = df

    mo.md(f"""
    ### ğŸ“Š é¸æŠæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿

    - **ã‚¤ãƒ™ãƒ³ãƒˆæ•°**: {len(filtered_df):,} / {len(df):,}
    """)
    return (filtered_df,)


@app.cell
def _(mo):
    mo.md(r"""
    ## ğŸš¨ å±é™ºãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³

    ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¸Šé‡è¦ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¤œå‡ºã—ã¾ã™ã€‚
    """)


@app.cell
def _():
    # Define dangerous actions
    DANGEROUS_ACTIONS = {
        "repo.destroy",
        "repo.archived",
        "repo.change_visibility",
        "org.remove_member",
        "team.destroy",
        "hook.create",
        "hook.destroy",
        "protected_branch.destroy",
        "secret_scanning.disable",
    }

    HIGH_RISK_ACTIONS = {
        "org.add_billing_manager",
        "org.promote_member_to_owner",
        "deploy_key.create",
        "integration_installation.create",
    }
    return DANGEROUS_ACTIONS, HIGH_RISK_ACTIONS


@app.cell
def _(DANGEROUS_ACTIONS, HIGH_RISK_ACTIONS, filtered_df, mo, pl):
    # Detect dangerous actions
    dangerous_events = filtered_df.filter(
        pl.col("action").is_in(list(DANGEROUS_ACTIONS))
    ).sort("timestamp", descending=True)

    high_risk_events = filtered_df.filter(
        pl.col("action").is_in(list(HIGH_RISK_ACTIONS))
    ).sort("timestamp", descending=True)

    dangerous_summary = mo.md(f"""
    ### æ¤œå‡ºçµæœ

    | ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ« | ä»¶æ•° |
    |------------|------|
    | ğŸ”´ Critical (å±é™º) | {len(dangerous_events)} |
    | ğŸŸ  High (é«˜ãƒªã‚¹ã‚¯) | {len(high_risk_events)} |
    """)

    if len(dangerous_events) > 0:
        dangerous_title = mo.md("### ğŸ”´ å±é™ºãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§")
        dangerous_table = mo.ui.table(dangerous_events, pagination=True, page_size=10)
        dangerous_result = mo.vstack(
            [dangerous_summary, dangerous_title, dangerous_table]
        )
    else:
        dangerous_message = mo.md("âœ… å±é™ºãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        dangerous_result = mo.vstack([dangerous_summary, dangerous_message])

    dangerous_result
    return dangerous_events, high_risk_events


@app.cell
def _(mo):
    mo.md(r"""
    ## ğŸŒ™ æ™‚é–“å¤–ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£

    å–¶æ¥­æ™‚é–“å¤–ï¼ˆ9:00å‰ã€18:00ä»¥é™ã€é€±æœ«ï¼‰ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã‚’æ¤œå‡ºã—ã¾ã™ã€‚
    """)


@app.cell
def _(df, mo, pl):
    # Detect off-hours activity
    off_hours_events = df.filter(
        (pl.col("timestamp").dt.hour() < 9)
        | (pl.col("timestamp").dt.hour() >= 18)
        | (pl.col("timestamp").dt.weekday() >= 5)
    )

    # Group by actor
    off_hours_by_actor = (
        off_hours_events.filter(
            ~pl.col("actor").str.contains(r"\[bot\]")
        )  # Exclude bots
        .group_by("actor")
        .agg(pl.len().alias("off_hours_count"))
        .sort("off_hours_count", descending=True)
        .head(10)
    )

    mo.md(f"""
    ### æ™‚é–“å¤–ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£çµ±è¨ˆ

    - **æ™‚é–“å¤–ã‚¤ãƒ™ãƒ³ãƒˆç·æ•°**: {len(off_hours_events):,}
    - **å…¨ä½“ã«å ã‚ã‚‹å‰²åˆ**: {len(off_hours_events) / len(df) * 100:.1f}%
    """)
    return off_hours_by_actor, off_hours_events


@app.cell
def _(alt, mo, off_hours_by_actor):
    if len(off_hours_by_actor) > 0:
        off_hours_chart = (
            alt.Chart(alt.Data(values=off_hours_by_actor.to_dicts()))
            .mark_bar()
            .encode(
                x=alt.X("off_hours_count:Q", title="æ™‚é–“å¤–ã‚¤ãƒ™ãƒ³ãƒˆæ•°"),
                y=alt.Y("actor:N", sort="-x", title="ãƒ¦ãƒ¼ã‚¶ãƒ¼"),
                color=alt.value("#f58518"),
                tooltip=["actor:N", "off_hours_count:Q"],
            )
            .properties(
                title="æ™‚é–“å¤–ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ãŒå¤šã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼ˆBoté™¤å¤–ï¼‰",
                width=500,
                height=300,
            )
        )
        off_hours_result = mo.ui.altair_chart(off_hours_chart)
    else:
        off_hours_result = mo.md("æ™‚é–“å¤–ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")

    off_hours_result


@app.cell
def _(mo):
    mo.md(r"""
    ## ğŸ“Š å¤§é‡æ“ä½œã®æ¤œå‡º

    çŸ­æ™‚é–“ã§ã®å¤§é‡æ“ä½œã‚’æ¤œå‡ºã—ã¾ã™ã€‚
    """)


@app.cell
def _(mo):
    threshold_slider = mo.ui.slider(
        start=10, stop=200, step=10, value=50, label="é–¾å€¤ï¼ˆ1æ™‚é–“ã‚ãŸã‚Šã®ã‚¤ãƒ™ãƒ³ãƒˆæ•°ï¼‰"
    )
    threshold_slider
    return (threshold_slider,)


@app.cell
def _(df, mo, pl, threshold_slider):
    # Detect bulk operations
    bulk_ops = (
        df.with_columns(pl.col("timestamp").dt.truncate("1h").alias("hour_window"))
        .group_by(["actor", "action", "hour_window"])
        .agg(pl.len().alias("count"))
        .filter(pl.col("count") > threshold_slider.value)
        .sort("count", descending=True)
    )

    mo.md(f"""
    ### å¤§é‡æ“ä½œã®æ¤œå‡ºçµæœ

    é–¾å€¤: **{threshold_slider.value}ä»¶/æ™‚é–“**

    æ¤œå‡ºã•ã‚ŒãŸå¤§é‡æ“ä½œ: **{len(bulk_ops)}ä»¶**
    """)
    return (bulk_ops,)


@app.cell
def _(bulk_ops, mo):
    if len(bulk_ops) > 0:
        bulk_ops_result = mo.ui.table(bulk_ops, pagination=True, page_size=10)
    else:
        bulk_ops_result = mo.md("âœ… å¤§é‡æ“ä½œã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")

    bulk_ops_result


@app.cell
def _(mo):
    mo.md(r"""
    ## ğŸŒ IPã‚¢ãƒ‰ãƒ¬ã‚¹åˆ†æ

    è¤‡æ•°ã®IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ã„ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æ¤œå‡ºã—ã¾ã™ã€‚
    """)


@app.cell
def _(df, mo, pl):
    # IP analysis
    if "actor_ip" in df.columns:
        ip_analysis = (
            df.filter(pl.col("actor_ip").is_not_null())
            .group_by("actor")
            .agg(
                pl.n_unique("actor_ip").alias("unique_ips"),
                pl.col("actor_ip").unique().alias("ip_list"),
            )
            .filter(pl.col("unique_ips") > 2)
            .sort("unique_ips", descending=True)
        )

        if len(ip_analysis) > 0:
            ip_result = mo.md(f"""
            ### è¤‡æ•°IPã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹

            3ã¤ä»¥ä¸Šã®ç•°ãªã‚‹IPã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ã„ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼: **{len(ip_analysis)}äºº**
            """)
        else:
            ip_result = mo.md("âœ… ç•°å¸¸ãªIPãƒ‘ã‚¿ãƒ¼ãƒ³ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
    else:
        ip_analysis = None
        ip_result = mo.md("âš ï¸ IPã‚¢ãƒ‰ãƒ¬ã‚¹æƒ…å ±ãŒãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")

    ip_result
    return (ip_analysis,)


@app.cell
def _(ip_analysis, mo):
    if ip_analysis is not None and len(ip_analysis) > 0:
        ip_table_result = mo.ui.table(
            ip_analysis.select(["actor", "unique_ips"]),
            pagination=True,
            page_size=10,
        )
    ip_table_result


@app.cell
def _(
    bulk_ops,
    dangerous_events,
    high_risk_events,
    ip_analysis,
    mo,
    off_hours_events,
):
    # Overall risk summary
    critical_count = len(dangerous_events)
    high_count = len(high_risk_events) + len(bulk_ops)
    medium_count = len(off_hours_events) // 100  # Simplified metric

    total_risk_score = critical_count * 10 + high_count * 5 + medium_count

    if total_risk_score == 0:
        risk_level = "ğŸŸ¢ ä½ãƒªã‚¹ã‚¯"
        risk_color = "green"
    elif total_risk_score < 50:
        risk_level = "ğŸŸ¡ ä¸­ãƒªã‚¹ã‚¯"
        risk_color = "yellow"
    elif total_risk_score < 100:
        risk_level = "ğŸŸ  é«˜ãƒªã‚¹ã‚¯"
        risk_color = "orange"
    else:
        risk_level = "ğŸ”´ é‡å¤§ãƒªã‚¹ã‚¯"
        risk_color = "red"

    mo.md(f"""
    ---

    ## ğŸ“‹ ãƒªã‚¹ã‚¯ã‚µãƒãƒªãƒ¼

    | é …ç›® | å€¤ |
    |------|-----|
    | å…¨ä½“ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ« | **{risk_level}** |
    | ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ | {total_risk_score} |
    | å±é™ºã‚¢ã‚¯ã‚·ãƒ§ãƒ³ | {critical_count} |
    | é«˜ãƒªã‚¹ã‚¯ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ | {len(high_risk_events)} |
    | å¤§é‡æ“ä½œ | {len(bulk_ops)} |
    | æ™‚é–“å¤–ã‚¤ãƒ™ãƒ³ãƒˆ | {len(off_hours_events):,} |
    | è¤‡æ•°IPã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹ | {len(ip_analysis)} |
    """)


if __name__ == "__main__":
    app.run()
